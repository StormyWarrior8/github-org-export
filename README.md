# github-org-export
A script to organize repositories in an Org by size and request exports from the migration API

## Usage
This script requires two environment variables:
 - `GITHUB_TOKEN`
   
   A token generated by an administrator account for the organization
 - `GITHUB_ORG`
   
   The name of the github Org. e.g. somecorp

Additionally, there are adjustable variables at the beginning of the script. Of note, there are:
 - `EXPORT_SIZE`
   
   This needs to be kept 'under 5G'. Keeping this at or under 2G was good for my runs.
 - `LOCK_REPOSITORIES`
   
   This is false out of the box because you're doing dry runs first right? RIGHT?

With these variables reviewed, running the script is as easy as `python export_github_org.py`. Here's a description of what happens when the script runs:

 1. Request a list of all repositories. This is paginated as indicated by the response headers.
 2. Request each page of repositories, and write each page to the directory `repo_out` as page #.json
 3. Request a list of all users. This is also paginated, so we do the same thing as the repo list, and write those pages to `user_out`
 4. Json is great, but a bit overcomplicated for how the requests to the migration API are made. We extract the individual user names and drop them in a file alongside the script called `user_names.txt`. This isn't specifically needed to export, but may be good to have later.
 5. For the repositories, since we care about not only the name, but the size (which is in MB), we parse those two items out from each repository and store them in a dict as {'reponame': size} so we can build repo groupings without just crossing our fingers that randomly selected repos will be under a certain size.